{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 04. 분류\n",
    "## 01. 분류(Classification)의 개요\n",
    "- 지도학습 : 레이블, 즉 명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신러닝의 방식\n",
    "\n",
    "\n",
    "- 분류(Classification) : 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측\n",
    "    - 즉, 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것.\n",
    "    - 지도학습의 대표적인 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류의 머신러닝 알고리즘\n",
    "    - 베이즈 통계와 생성 모델에 기반한 나이브 베이즈(Naive Bayes)\n",
    "    - 독립변수와 종속변수 선형 관계성에 기반한 로지스틱 회귀(Logistic Regression)\n",
    "    - 데이터 균일도에 따른 규칙 기반의 결정 트리(Decision Tree)\n",
    "    - 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 서포트 벡터 머신(Support Vector Machine)\n",
    "    - 근접 거리를 기준으로 하는 최소 근접(Nearest Neighbor) 알고리즘\n",
    "    - 심층 연결 기반의 신경망(Neural Network)\n",
    "    - 서로 다른(또는 같은) 머신러닝 알고리즘을 결합한 앙상블(Ensemble)\n",
    "        - 분류에서 가장 각광을 받는 방법 중 하나. 정형 데이터의 예측 분석 영역에서 매우 높은 예측 성능으로 인해 애용되고 있다.\n",
    "        - 서로 다른(또는 같은) 알고리즘을 단순히 결합한 형태도 있으나, 배깅과 부스팅 방식이 일반적이다.\n",
    "            - 배깅 방식 : 대표적으로 랜덤 포레스트가 있다.(앙상블의 기본 알고리즘으로, 일반적으로 사용함) 뛰어난 예측 성능, 상대적으로 빠른 수행 시간, 유연성 등으로 많은 분석가가 애용하는 알고리즘이다.\n",
    "            - 부스팅 방식 : 근래의 앙상블 방법은 부스팅 방식으로 지속해서 발전하고 있다. 그래디언 부스팅의 경우 계속적으로 발전된 알고리즘이 등장하면서 정형 데이터의 분류 영역에서 가장 활용도가 높은 알고리즘으로 자리 잡았다.\n",
    "        - 결정 트리와 앙상블\n",
    "            - 결정 트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘이다. 또한 데이터의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적다.\n",
    "                - 하지만 예측 성능을 향상시키기 위해 복잡한 규칙구조를 가져야 하며, 이로 인한 과적합이 발생해 반대로 예측 성능이 저하될 수도 있다는 단점이 있다.(하지만 이러한 단점이 앙상블 기법에서는 오히려 장점으로 작용)\n",
    "            - 앙상블은 매우 많은 여러개의 약한 학습기(즉, 예측 성능이 상대적으로 떨어지는 학습 알고리즘)를 결합해 확률적 보완과 오류가 발생한 부분에 대한 가중치를 계속 업데이트하면서 예측 성을을 향상시키는데, 결정트리가 좋은 약한 학습기가 되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.결정트리\n",
    ": 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만드는 것. ML 알고리즘 중 직관적으로 이해하기 쉬운 알고리즘.\n",
    "- 데이터의 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능을 크게 좌우한다.\n",
    "- 결정 트리의 구조\n",
    "    - 규칙 노드(Decision Node)로 표시된 노드 -> 규칙 조건\n",
    "    - 리프 노드(Leaf Node)로 표시된 노드 -> 결정된 클래스 값\n",
    "    - 서브 트리(Sub Tree) : 새로운 규칙 조건마다 생성됨\n",
    "- 데이터 세트에 피처가 있고 이러한 피처가 결합해 규칙 조건을 만들 때마다 규칙노드가 만들어진다. \n",
    "- 하지만, 많은 규칙이 있다는 것은 곧 분류를 결정하는 방식이 더욱 복잡해진다는 이야기이고, 이는 곧 과적합으로 이어진다. \n",
    "- 즉, 트리의 깊이가 깊어질수록 결정 트리의 예측 성능이 저하될 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가능한 적은 결정 노드로 높은 예측 정확도를 가지려면\n",
    ": 데이터를 분류할 때 최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 결정 노드의 규칙이 정해져야 한다.\n",
    "- 이를 위해서는 어떻게 트리를 분할할 것인가가 중요. 최대한 균일한 데이터 세트를 구성할 수 있도록 분할하는 것이 필요\n",
    "    - 데이터 세트의 균일도는 데이터를 구분하는 데 필요한 정보의 양에 영향을 미친다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결정 노드\n",
    ": 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만듭니다. 즉, 정보 균일도가 데이터 세트로 쪼개질 수 있도록 조건을 찾아 서브 데이터 세트를 만들고, 다시 이 서브 데이터 세트에서 균일도가 높은 자식 데이터 세트 쪼개는 방식을 자식 트리로 내려가면서 반복하는 방식으로 데이터 값을 예측하게 된다. \n",
    "##### 정보의 균일도를 측정하는 대표적인 방법 : 엔트로피를 이용한 정보이득 지수, 지니 계수\n",
    "- 정보이득 : 엔트로피라는 개념을 기반으로 한다. 1-엔트로피 지수. 결정트리는 이 정보 이득 지수로 분할 기준을 정한다. 즉, 정보 이득이 높은 속성을 기준으로 분할\n",
    "    - 엔트로피 : 주어진 데이터 집합의 혼잡도. 서로 다른 값이 섞여있으면 엔트로피가 높다.\n",
    "- 지니 계수  : 불평등 지수를 나타낼 때 사용하는 계수이다. 0이 가장 평등 1로 갈수록 불평등. 지니 계수가 낮을수록 데이터 균일도가 높은 것으로 해석해 지니 계수가 낮은 속성을 기준으로 분할한다.\n",
    "    - DecisionTreeClassifier는 기본으로 지니계수를 이용해 데이터 세트를 분할한다.\n",
    "    \n",
    "\n",
    "- 결정 트리의 일반적인 알고리즘은 정보 이득이 높거나 지니 계수가 낮은 조건을 찾아서 자식 트리 노드에 걸쳐 반복적으로 분할한뒤, 데이터가 모두 특정 분류에 속하게 되면 분할을 멈추고 분류를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 모델의 특징\n",
    "#### 장점 \n",
    ": 정보의 균일도라는 룰을 기반으로 하고 있어서 알고리즘이 쉽고 직관적이다. 피처의 스케일링이나 정규화 등의 사전 가공 영향도가 크지안핟. \n",
    "#### 단점\n",
    ": 과적합으로 정확도가 떨어진다. 이를 극복하기 위해 트리의 크기를 사전에 제한하는 튜닝 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 파라미터\n",
    "-  DecisionTreeClassfier  : 분류를 위한 클래스\n",
    "- DecisionTreeRegressor : 회귀를 위한 클래스\n",
    "- 사이킷런의 결정 트리 구현은 CART(Classification And Regression Trees) 알고리즘 기반이다. 이는 분류뿐만 아니라 회귀에서도 사용될 수 있는 트리 알고리즘이다.\n",
    "\n",
    "#### 파라미터\n",
    "- min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터 수. 과적합을 제어하는데 사용\n",
    "    - 디폴트 2. 작게 설정할수록 분할되는 노드가 많아져서 과적합 가능성 증가.\n",
    "- min_samples_leaf : 말단 노드(leaf)가 되기 위한 최소한의 샘플 데이터 수. \n",
    "    - 과적합 제어 용도. \n",
    "    - 비대칭적 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 이 경우는 작게 설정 필요\n",
    "- max_features : 최적의 분할을 위해 고려할 최대 피처 개수. 디폴트는 None으로 데이터 세트의 모든 피처를 사용해 분할 수행\n",
    "    - int: 대상피처의 개수 / float: 전체 피처 중 대상 피처의 퍼센트 / sqrt: 전체 피처 중 sqrt(전체피처개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 피처명에서 10개만 추출: ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\n",
    "feature_name_df = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "\n",
    "# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "print('전체 피처명에서 10개만 추출:', feature_name[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**중복된 피처명을 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_index    42\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-17,24</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-17,32</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column_index\n",
       "column_name                               \n",
       "fBodyAcc-bandsEnergy()-1,16              3\n",
       "fBodyAcc-bandsEnergy()-1,24              3\n",
       "fBodyAcc-bandsEnergy()-1,8               3\n",
       "fBodyAcc-bandsEnergy()-17,24             3\n",
       "fBodyAcc-bandsEnergy()-17,32             3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dup_df = feature_name_df.groupby('column_name').count()\n",
    "print(feature_dup_df[feature_dup_df['column_index'] > 1].count())\n",
    "feature_dup_df[feature_dup_df['column_index'] > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] =  new_feature_name_df['column_name'].astype('U32')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_human_dataset():\n",
    "    \n",
    "    feature_name_df = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/features.txt', sep='/s+', \n",
    "                                 header = None, names = ['column_index', 'column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame 생성\n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 칼럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터세트와 테스트 피처 데이터를 DataFrame으로 로딩. 칼럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/train/X_train.txt', sep='/s+', names = feature_name)\n",
    "    X_test = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/test/X_test.txt', sep='/s+', names = feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터를 DataFrame으로 로딩하고 칼럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/train/y_train.txt', sep='/s+', header = None, names = ['action'])\n",
    "    y_test = pd.read_csv('./Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/human_activity/test/y_test.txt', sep='/s+', header = None, names = ['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. GBM(Gradient Boosting Machine)\n",
    "### GBM의 개요 및 실습 \n",
    "#### 부스팅의 대표적인 구현\n",
    "- AdaBoost(Adaptive Boosting)\n",
    "    - 오류 데이터에 가중치를 부여하면서 부스팅을 수행하는 대표적인 알고리즘\n",
    "    - 즉, 약한 학습기가 순차적으로 오류 값에 대해 가중치를 부여한 예측 결정 기준을 모두 결합해 예측을 수행한다.\n",
    "    - 예를 들어 첫번째 학습기에 가중치 0.3 두번째에는 0.5 세번째에는 0.8을 부여한 후 모두 결합해 예측을 수행한다.\n",
    "    \n",
    "    \n",
    "- GBM(Gradient Boost Machine) \n",
    "    - 에이다부스트와 유사하나, 가중치 업데이트를 경사 하강법(Gradient Descent)을 이용하는 것이 큰 차이이다.\n",
    "        - 오류값 : 실제값 - 예측값\n",
    "        - 경사 하강법 : 오류값을 최소화하는 방향성을 가지고 반복적으로 가중치 값을 업데이트 하는 것\n",
    "    - 분류는 물론, 회귀도 가능\n",
    "    - GradientBoostingClassifier 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2.8858451e-001 -2.0294171e-002 -1.3290514e-001 -9.9527860e-001 -9.8311061e-001 -9.1352645e-001 -9.9511208e-001 -9.8318457e-001 -9.2352702e-001 -9.3472378e-001 -5.6737807e-001 -7.4441253e-001  8.5294738e-001  6.8584458e-001  8.1426278e-001 -9.6552279e-001 -9.9994465e-001 -9.9986303e-001 -9.9461218e-001 -9.9423081e-001 -9.8761392e-001 -9.4321999e-001 -4.0774707e-001 -6.7933751e-001 -6.0212187e-001  9.2929351e-001 -8.5301114e-001  3.5990976e-001 -5.8526382e-002  2.5689154e-001 -2.2484763e-001  2.6410572e-001 -9.5245630e-002  2.7885143e-001 -4.6508457e-001  4.9193596e-001 -1.9088356e-001  3.7631389e-001  4.3512919e-001  6.6079033e-001  9.6339614e-001 -1.4083968e-001  1.1537494e-001 -9.8524969e-001 -9.8170843e-001 -8.7762497e-001 -9.8500137e-001 -9.8441622e-001 -8.9467735e-001  8.9205451e-001 -1.6126549e-001  1.2465977e-001  9.7743631e-001 -1.2321341e-001  5.6482734e-002 -3.7542596e-001  8.9946864e-001 -9.7090521e-001 -9.7551037e-001 -9.8432539e-001 -9.8884915e-001 -9.1774264e-001 -1.0000000e+000 -1.0000000e+000  1.1380614e-001 -5.9042500e-001  5.9114630e-001 -5.9177346e-001  5.9246928e-001 -7.4544878e-001  7.2086167e-001 -7.1237239e-001  7.1130003e-001 -9.9511159e-001  9.9567491e-001 -9.9566759e-001  9.9165268e-001  5.7022164e-001  4.3902735e-001  9.8691312e-001  7.7996345e-002  5.0008031e-003 -6.7830808e-002 -9.9351906e-001 -9.8835999e-001 -9.9357497e-001 -9.9448763e-001 -9.8620664e-001 -9.9281835e-001 -9.8518010e-001 -9.9199423e-001 -9.9311887e-001  9.8983471e-001  9.9195686e-001  9.9051920e-001 -9.9352201e-001 -9.9993487e-001 -9.9982045e-001 -9.9987846e-001 -9.9436404e-001 -9.8602487e-001 -9.8923361e-001 -8.1994925e-001 -7.9304645e-001 -8.8885295e-001  1.0000000e+000 -2.2074703e-001  6.3683075e-001  3.8764356e-001  2.4140146e-001 -5.2252848e-002  2.6417720e-001  3.7343945e-001  3.4177752e-001 -5.6979119e-001  2.6539882e-001 -4.7787489e-001 -3.8530050e-001  3.3643943e-002 -1.2651082e-001 -6.1008489e-003 -3.1364791e-002  1.0772540e-001 -9.8531027e-001 -9.7662344e-001 -9.9220528e-001 -9.8458626e-001 -9.7635262e-001 -9.9236164e-001 -8.6704374e-001 -9.3378602e-001 -7.4756618e-001  8.4730796e-001  9.1489534e-001  8.3084054e-001 -9.6718428e-001 -9.9957831e-001 -9.9935432e-001 -9.9976339e-001 -9.8343808e-001 -9.7861401e-001 -9.9296558e-001  8.2631682e-002  2.0226765e-001 -1.6875669e-001  9.6323236e-002 -2.7498511e-001  4.9864419e-001 -2.2031685e-001  1.0000000e+000 -9.7297139e-001  3.1665451e-001  3.7572641e-001  7.2339919e-001 -7.7111201e-001  6.9021323e-001 -3.3183104e-001  7.0958377e-001  1.3487336e-001  3.0109948e-001 -9.9167400e-002 -5.5517369e-002 -6.1985797e-002 -9.9211067e-001 -9.9251927e-001 -9.9205528e-001 -9.9216475e-001 -9.9494156e-001 -9.9261905e-001 -9.9015585e-001 -9.8674277e-001 -9.9204155e-001  9.9442876e-001  9.9175581e-001  9.8935195e-001 -9.9445335e-001 -9.9993755e-001 -9.9995350e-001 -9.9992294e-001 -9.9229974e-001 -9.9693892e-001 -9.9224298e-001 -5.8985096e-001 -6.8845905e-001 -5.7210686e-001  2.9237634e-001 -3.6199802e-001  4.0554269e-001 -3.9006951e-002  9.8928381e-001 -4.1456048e-001  3.9160251e-001  2.8225087e-001  9.2726984e-001 -5.7237001e-001  6.9161920e-001  4.6828982e-001 -1.3107697e-001 -8.7159695e-002  3.3624748e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.9330586e-001 -9.9433641e-001 -9.9450037e-001 -9.9278399e-001 -9.9120847e-001 -9.9330586e-001 -9.9989188e-001 -9.9293370e-001 -8.6341476e-001  2.8308522e-001 -2.3730869e-001 -1.0543219e-001 -3.8212313e-002 -9.6895908e-001 -9.6433518e-001 -9.5724477e-001 -9.7505986e-001 -9.9155366e-001 -9.6895908e-001 -9.9928646e-001 -9.4976582e-001  7.2579035e-002  5.7251142e-001 -7.3860219e-001  2.1257776e-001  4.3340495e-001 -9.9424782e-001 -9.9136761e-001 -9.9314298e-001 -9.8893563e-001 -9.9348603e-001 -9.9424782e-001 -9.9994898e-001 -9.9454718e-001 -6.1976763e-001  2.9284049e-001 -1.7688920e-001 -1.4577921e-001 -1.2407233e-001 -9.9478319e-001 -9.8298410e-001 -9.3926865e-001 -9.9542175e-001 -9.8313297e-001 -9.0616498e-001 -9.9688864e-001 -9.8451927e-001 -9.3208200e-001 -9.9375634e-001 -9.8316285e-001 -8.8505422e-001 -9.9396185e-001 -9.9344611e-001 -9.2342772e-001 -9.7473271e-001 -9.9996838e-001 -9.9968911e-001 -9.9489148e-001 -9.9592602e-001 -9.8970889e-001 -9.8799115e-001 -9.4635692e-001 -9.0474776e-001 -5.9130248e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  2.5248290e-001  1.3183575e-001 -5.2050251e-002  1.4205056e-001 -1.5068250e-001 -2.2054694e-001 -5.5873853e-001  2.4676868e-001 -7.4155206e-003 -9.9996279e-001 -9.9998650e-001 -9.9997907e-001 -9.9996244e-001 -9.9993222e-001 -9.9972512e-001 -9.9967039e-001 -9.9998582e-001 -9.9996867e-001 -9.9997686e-001 -9.9986966e-001 -9.9977613e-001 -9.9997115e-001 -9.9991925e-001 -9.9965680e-001 -9.9986046e-001 -9.9986695e-001 -9.9986301e-001 -9.9973783e-001 -9.9973220e-001 -9.9949261e-001 -9.9981364e-001 -9.9968182e-001 -9.9983940e-001 -9.9973823e-001 -9.9961197e-001 -9.9968721e-001 -9.9983863e-001 -9.9359234e-001 -9.9947584e-001 -9.9966204e-001 -9.9964230e-001 -9.9929341e-001 -9.9789222e-001 -9.9593249e-001 -9.9514642e-001 -9.9473990e-001 -9.9968826e-001 -9.9892456e-001 -9.9567134e-001 -9.9487731e-001 -9.9945439e-001 -9.9233245e-001 -9.8716991e-001 -9.8969609e-001 -9.9582068e-001 -9.9093631e-001 -9.9705167e-001 -9.9380547e-001 -9.9051869e-001 -9.9699279e-001 -9.9673689e-001 -9.9197516e-001 -9.9324167e-001 -9.9834907e-001 -9.9110842e-001 -9.5988537e-001 -9.9051499e-001 -9.9993475e-001 -9.9982048e-001 -9.9988449e-001 -9.9302626e-001 -9.9137339e-001 -9.9623962e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  1.0000000e+000 -2.4000000e-001 -1.0000000e+000  8.7038451e-001  2.1069700e-001  2.6370789e-001 -7.0368577e-001 -9.0374251e-001 -5.8257362e-001 -9.3631005e-001 -5.0734474e-001 -8.0553591e-001 -9.9998649e-001 -9.9997960e-001 -9.9997478e-001 -9.9995513e-001 -9.9991861e-001 -9.9964011e-001 -9.9948330e-001 -9.9996087e-001 -9.9998227e-001 -9.9997072e-001 -9.9981098e-001 -9.9948472e-001 -9.9998083e-001 -9.9985189e-001 -9.9993261e-001 -9.9989993e-001 -9.9982444e-001 -9.9985982e-001 -9.9972751e-001 -9.9972876e-001 -9.9956707e-001 -9.9976524e-001 -9.9990021e-001 -9.9981490e-001 -9.9970980e-001 -9.9959608e-001 -9.9985216e-001 -9.9982210e-001 -9.9939988e-001 -9.9976559e-001 -9.9995846e-001 -9.9994951e-001 -9.9983850e-001 -9.9981351e-001 -9.9878054e-001 -9.9857783e-001 -9.9961968e-001 -9.9998359e-001 -9.9982812e-001 -9.9868068e-001 -9.9984416e-001 -9.9992792e-001 -9.8657442e-001 -9.8176153e-001 -9.8951478e-001 -9.8503264e-001 -9.7388607e-001 -9.9403493e-001 -9.8653085e-001 -9.8361636e-001 -9.9235201e-001 -9.8049843e-001 -9.7227092e-001 -9.9494426e-001 -9.9756862e-001 -9.8408510e-001 -9.9433541e-001 -9.8527621e-001 -9.9986371e-001 -9.9966608e-001 -9.9993462e-001 -9.9034389e-001 -9.9483569e-001 -9.9441158e-001 -7.1240225e-001 -6.4484236e-001 -8.3899298e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000 -2.5754888e-001  9.7947109e-002  5.4715105e-001  3.7731121e-001  1.3409154e-001  2.7337197e-001 -9.1261831e-002 -4.8434650e-001 -7.8285070e-001 -9.9986502e-001 -9.9993178e-001 -9.9997295e-001 -9.9997018e-001 -9.9993012e-001 -9.9995862e-001 -9.9992899e-001 -9.9998465e-001 -9.9986326e-001 -9.9996815e-001 -9.9993610e-001 -9.9995363e-001 -9.9986442e-001 -9.9996098e-001 -9.9945373e-001 -9.9997811e-001 -9.9999153e-001 -9.9999010e-001 -9.9996857e-001 -9.9980657e-001 -9.9834600e-001 -9.9896122e-001 -9.9961874e-001 -9.9998934e-001 -9.9993540e-001 -9.9838752e-001 -9.9964264e-001 -9.9997266e-001 -9.9995535e-001 -9.9997630e-001 -9.9990583e-001 -9.9998550e-001 -9.9993717e-001 -9.9975115e-001 -9.9907227e-001 -9.9992754e-001 -9.9995158e-001 -9.9990585e-001 -9.9989269e-001 -9.9944433e-001 -9.9994099e-001 -9.9995861e-001 -9.5215466e-001 -9.5613397e-001 -9.4887014e-001 -9.7432057e-001 -9.2572179e-001 -9.5215466e-001 -9.9828520e-001 -9.7327320e-001 -6.4637645e-001 -7.9310345e-001 -8.8436120e-002 -4.3647104e-001 -7.9684048e-001 -9.9372565e-001 -9.9375495e-001 -9.9197570e-001 -9.9336472e-001 -9.8817543e-001 -9.9372565e-001 -9.9991844e-001 -9.9136366e-001 -1.0000000e+000 -9.3650794e-001  3.4698853e-001 -5.1608015e-001 -8.0276003e-001 -9.8013485e-001 -9.6130944e-001 -9.7365344e-001 -9.5226383e-001 -9.8949813e-001 -9.8013485e-001 -9.9924035e-001 -9.9265553e-001 -7.0129141e-001 -1.0000000e+000 -1.2898890e-001  5.8615643e-001  3.7460462e-001 -9.9199044e-001 -9.9069746e-001 -9.8994084e-001 -9.9244784e-001 -9.9104773e-001 -9.9199044e-001 -9.9993676e-001 -9.9045792e-001 -8.7130580e-001 -1.0000000e+000 -7.4323027e-002 -2.9867637e-001 -7.1030407e-001 -1.1275434e-001  3.0400372e-002 -4.6476139e-001 -1.8445884e-002 -8.4124676e-001  1.7994061e-001 -5.8626924e-002'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-cd842b496d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgb_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mgb_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[1;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2.8858451e-001 -2.0294171e-002 -1.3290514e-001 -9.9527860e-001 -9.8311061e-001 -9.1352645e-001 -9.9511208e-001 -9.8318457e-001 -9.2352702e-001 -9.3472378e-001 -5.6737807e-001 -7.4441253e-001  8.5294738e-001  6.8584458e-001  8.1426278e-001 -9.6552279e-001 -9.9994465e-001 -9.9986303e-001 -9.9461218e-001 -9.9423081e-001 -9.8761392e-001 -9.4321999e-001 -4.0774707e-001 -6.7933751e-001 -6.0212187e-001  9.2929351e-001 -8.5301114e-001  3.5990976e-001 -5.8526382e-002  2.5689154e-001 -2.2484763e-001  2.6410572e-001 -9.5245630e-002  2.7885143e-001 -4.6508457e-001  4.9193596e-001 -1.9088356e-001  3.7631389e-001  4.3512919e-001  6.6079033e-001  9.6339614e-001 -1.4083968e-001  1.1537494e-001 -9.8524969e-001 -9.8170843e-001 -8.7762497e-001 -9.8500137e-001 -9.8441622e-001 -8.9467735e-001  8.9205451e-001 -1.6126549e-001  1.2465977e-001  9.7743631e-001 -1.2321341e-001  5.6482734e-002 -3.7542596e-001  8.9946864e-001 -9.7090521e-001 -9.7551037e-001 -9.8432539e-001 -9.8884915e-001 -9.1774264e-001 -1.0000000e+000 -1.0000000e+000  1.1380614e-001 -5.9042500e-001  5.9114630e-001 -5.9177346e-001  5.9246928e-001 -7.4544878e-001  7.2086167e-001 -7.1237239e-001  7.1130003e-001 -9.9511159e-001  9.9567491e-001 -9.9566759e-001  9.9165268e-001  5.7022164e-001  4.3902735e-001  9.8691312e-001  7.7996345e-002  5.0008031e-003 -6.7830808e-002 -9.9351906e-001 -9.8835999e-001 -9.9357497e-001 -9.9448763e-001 -9.8620664e-001 -9.9281835e-001 -9.8518010e-001 -9.9199423e-001 -9.9311887e-001  9.8983471e-001  9.9195686e-001  9.9051920e-001 -9.9352201e-001 -9.9993487e-001 -9.9982045e-001 -9.9987846e-001 -9.9436404e-001 -9.8602487e-001 -9.8923361e-001 -8.1994925e-001 -7.9304645e-001 -8.8885295e-001  1.0000000e+000 -2.2074703e-001  6.3683075e-001  3.8764356e-001  2.4140146e-001 -5.2252848e-002  2.6417720e-001  3.7343945e-001  3.4177752e-001 -5.6979119e-001  2.6539882e-001 -4.7787489e-001 -3.8530050e-001  3.3643943e-002 -1.2651082e-001 -6.1008489e-003 -3.1364791e-002  1.0772540e-001 -9.8531027e-001 -9.7662344e-001 -9.9220528e-001 -9.8458626e-001 -9.7635262e-001 -9.9236164e-001 -8.6704374e-001 -9.3378602e-001 -7.4756618e-001  8.4730796e-001  9.1489534e-001  8.3084054e-001 -9.6718428e-001 -9.9957831e-001 -9.9935432e-001 -9.9976339e-001 -9.8343808e-001 -9.7861401e-001 -9.9296558e-001  8.2631682e-002  2.0226765e-001 -1.6875669e-001  9.6323236e-002 -2.7498511e-001  4.9864419e-001 -2.2031685e-001  1.0000000e+000 -9.7297139e-001  3.1665451e-001  3.7572641e-001  7.2339919e-001 -7.7111201e-001  6.9021323e-001 -3.3183104e-001  7.0958377e-001  1.3487336e-001  3.0109948e-001 -9.9167400e-002 -5.5517369e-002 -6.1985797e-002 -9.9211067e-001 -9.9251927e-001 -9.9205528e-001 -9.9216475e-001 -9.9494156e-001 -9.9261905e-001 -9.9015585e-001 -9.8674277e-001 -9.9204155e-001  9.9442876e-001  9.9175581e-001  9.8935195e-001 -9.9445335e-001 -9.9993755e-001 -9.9995350e-001 -9.9992294e-001 -9.9229974e-001 -9.9693892e-001 -9.9224298e-001 -5.8985096e-001 -6.8845905e-001 -5.7210686e-001  2.9237634e-001 -3.6199802e-001  4.0554269e-001 -3.9006951e-002  9.8928381e-001 -4.1456048e-001  3.9160251e-001  2.8225087e-001  9.2726984e-001 -5.7237001e-001  6.9161920e-001  4.6828982e-001 -1.3107697e-001 -8.7159695e-002  3.3624748e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.9330586e-001 -9.9433641e-001 -9.9450037e-001 -9.9278399e-001 -9.9120847e-001 -9.9330586e-001 -9.9989188e-001 -9.9293370e-001 -8.6341476e-001  2.8308522e-001 -2.3730869e-001 -1.0543219e-001 -3.8212313e-002 -9.6895908e-001 -9.6433518e-001 -9.5724477e-001 -9.7505986e-001 -9.9155366e-001 -9.6895908e-001 -9.9928646e-001 -9.4976582e-001  7.2579035e-002  5.7251142e-001 -7.3860219e-001  2.1257776e-001  4.3340495e-001 -9.9424782e-001 -9.9136761e-001 -9.9314298e-001 -9.8893563e-001 -9.9348603e-001 -9.9424782e-001 -9.9994898e-001 -9.9454718e-001 -6.1976763e-001  2.9284049e-001 -1.7688920e-001 -1.4577921e-001 -1.2407233e-001 -9.9478319e-001 -9.8298410e-001 -9.3926865e-001 -9.9542175e-001 -9.8313297e-001 -9.0616498e-001 -9.9688864e-001 -9.8451927e-001 -9.3208200e-001 -9.9375634e-001 -9.8316285e-001 -8.8505422e-001 -9.9396185e-001 -9.9344611e-001 -9.2342772e-001 -9.7473271e-001 -9.9996838e-001 -9.9968911e-001 -9.9489148e-001 -9.9592602e-001 -9.8970889e-001 -9.8799115e-001 -9.4635692e-001 -9.0474776e-001 -5.9130248e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  2.5248290e-001  1.3183575e-001 -5.2050251e-002  1.4205056e-001 -1.5068250e-001 -2.2054694e-001 -5.5873853e-001  2.4676868e-001 -7.4155206e-003 -9.9996279e-001 -9.9998650e-001 -9.9997907e-001 -9.9996244e-001 -9.9993222e-001 -9.9972512e-001 -9.9967039e-001 -9.9998582e-001 -9.9996867e-001 -9.9997686e-001 -9.9986966e-001 -9.9977613e-001 -9.9997115e-001 -9.9991925e-001 -9.9965680e-001 -9.9986046e-001 -9.9986695e-001 -9.9986301e-001 -9.9973783e-001 -9.9973220e-001 -9.9949261e-001 -9.9981364e-001 -9.9968182e-001 -9.9983940e-001 -9.9973823e-001 -9.9961197e-001 -9.9968721e-001 -9.9983863e-001 -9.9359234e-001 -9.9947584e-001 -9.9966204e-001 -9.9964230e-001 -9.9929341e-001 -9.9789222e-001 -9.9593249e-001 -9.9514642e-001 -9.9473990e-001 -9.9968826e-001 -9.9892456e-001 -9.9567134e-001 -9.9487731e-001 -9.9945439e-001 -9.9233245e-001 -9.8716991e-001 -9.8969609e-001 -9.9582068e-001 -9.9093631e-001 -9.9705167e-001 -9.9380547e-001 -9.9051869e-001 -9.9699279e-001 -9.9673689e-001 -9.9197516e-001 -9.9324167e-001 -9.9834907e-001 -9.9110842e-001 -9.5988537e-001 -9.9051499e-001 -9.9993475e-001 -9.9982048e-001 -9.9988449e-001 -9.9302626e-001 -9.9137339e-001 -9.9623962e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  1.0000000e+000 -2.4000000e-001 -1.0000000e+000  8.7038451e-001  2.1069700e-001  2.6370789e-001 -7.0368577e-001 -9.0374251e-001 -5.8257362e-001 -9.3631005e-001 -5.0734474e-001 -8.0553591e-001 -9.9998649e-001 -9.9997960e-001 -9.9997478e-001 -9.9995513e-001 -9.9991861e-001 -9.9964011e-001 -9.9948330e-001 -9.9996087e-001 -9.9998227e-001 -9.9997072e-001 -9.9981098e-001 -9.9948472e-001 -9.9998083e-001 -9.9985189e-001 -9.9993261e-001 -9.9989993e-001 -9.9982444e-001 -9.9985982e-001 -9.9972751e-001 -9.9972876e-001 -9.9956707e-001 -9.9976524e-001 -9.9990021e-001 -9.9981490e-001 -9.9970980e-001 -9.9959608e-001 -9.9985216e-001 -9.9982210e-001 -9.9939988e-001 -9.9976559e-001 -9.9995846e-001 -9.9994951e-001 -9.9983850e-001 -9.9981351e-001 -9.9878054e-001 -9.9857783e-001 -9.9961968e-001 -9.9998359e-001 -9.9982812e-001 -9.9868068e-001 -9.9984416e-001 -9.9992792e-001 -9.8657442e-001 -9.8176153e-001 -9.8951478e-001 -9.8503264e-001 -9.7388607e-001 -9.9403493e-001 -9.8653085e-001 -9.8361636e-001 -9.9235201e-001 -9.8049843e-001 -9.7227092e-001 -9.9494426e-001 -9.9756862e-001 -9.8408510e-001 -9.9433541e-001 -9.8527621e-001 -9.9986371e-001 -9.9966608e-001 -9.9993462e-001 -9.9034389e-001 -9.9483569e-001 -9.9441158e-001 -7.1240225e-001 -6.4484236e-001 -8.3899298e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000 -2.5754888e-001  9.7947109e-002  5.4715105e-001  3.7731121e-001  1.3409154e-001  2.7337197e-001 -9.1261831e-002 -4.8434650e-001 -7.8285070e-001 -9.9986502e-001 -9.9993178e-001 -9.9997295e-001 -9.9997018e-001 -9.9993012e-001 -9.9995862e-001 -9.9992899e-001 -9.9998465e-001 -9.9986326e-001 -9.9996815e-001 -9.9993610e-001 -9.9995363e-001 -9.9986442e-001 -9.9996098e-001 -9.9945373e-001 -9.9997811e-001 -9.9999153e-001 -9.9999010e-001 -9.9996857e-001 -9.9980657e-001 -9.9834600e-001 -9.9896122e-001 -9.9961874e-001 -9.9998934e-001 -9.9993540e-001 -9.9838752e-001 -9.9964264e-001 -9.9997266e-001 -9.9995535e-001 -9.9997630e-001 -9.9990583e-001 -9.9998550e-001 -9.9993717e-001 -9.9975115e-001 -9.9907227e-001 -9.9992754e-001 -9.9995158e-001 -9.9990585e-001 -9.9989269e-001 -9.9944433e-001 -9.9994099e-001 -9.9995861e-001 -9.5215466e-001 -9.5613397e-001 -9.4887014e-001 -9.7432057e-001 -9.2572179e-001 -9.5215466e-001 -9.9828520e-001 -9.7327320e-001 -6.4637645e-001 -7.9310345e-001 -8.8436120e-002 -4.3647104e-001 -7.9684048e-001 -9.9372565e-001 -9.9375495e-001 -9.9197570e-001 -9.9336472e-001 -9.8817543e-001 -9.9372565e-001 -9.9991844e-001 -9.9136366e-001 -1.0000000e+000 -9.3650794e-001  3.4698853e-001 -5.1608015e-001 -8.0276003e-001 -9.8013485e-001 -9.6130944e-001 -9.7365344e-001 -9.5226383e-001 -9.8949813e-001 -9.8013485e-001 -9.9924035e-001 -9.9265553e-001 -7.0129141e-001 -1.0000000e+000 -1.2898890e-001  5.8615643e-001  3.7460462e-001 -9.9199044e-001 -9.9069746e-001 -9.8994084e-001 -9.9244784e-001 -9.9104773e-001 -9.9199044e-001 -9.9993676e-001 -9.9045792e-001 -8.7130580e-001 -1.0000000e+000 -7.4323027e-002 -2.9867637e-001 -7.1030407e-001 -1.1275434e-001  3.0400372e-002 -4.6476139e-001 -1.8445884e-002 -8.4124676e-001  1.7994061e-001 -5.8626924e-002'"
     ]
    }
   ],
   "source": [
    "# 사용자 행동 데이터 세트 예측 분류\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행시간 측정을 취함. 시작 시간 설정\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print('GBM 수행 시간: {0:.1f} 초'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로, GBM이 랜덤 포레스트보다는 예측 성능이 조금 뛰어난 경우가 많다.\n",
    "\n",
    "그러나 수행시간이 오래 걸리고(GBM이 극복해야 할 중요한 과제), 하이퍼 파라미터 튜닝 노력도 더 필요하다.\n",
    "(반면에 랜덤 포레스트는 상대적으로 빠른 수행 시간을 보장해주기 떄문에 더 쉽게 예측 결과 도출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM 하이퍼 파라미터 튜닝\n",
    "- loss : 경사 하강법에서 사용할 비용함수 지정(default : deviance)\n",
    "\n",
    "\n",
    "- learning rage : GBMdㅣ 학습을 진행할 때마다 적용하는 학습률. weak learner가 순차적으로 오류 값을 보정해 나가는 데 적용하는 계수.\n",
    "    - 0~1 사이 값을 지정할 수 있으며, 기본값은 0.1이다.\n",
    "    - 너무 작은 값 적용할 시 : \n",
    "        - 업데이트 되는 값이 작아져 최소 오류 값을 찾아 예측 성능이 높아질 가능성 높다.\n",
    "        - 모든 weak learner의 반복이 완료돼도 최소 오류 값을 찾지 못할 수 있다.\n",
    "    - 많은 weak learner :\n",
    "        - 순차적인 반복이 필요해 수행시간이 오래걸린다.\n",
    "        - 최소 오류 값을 찾지 못하고 그냥 지나쳐버려 예측 성능이 떨어질 가능성이 높아지지만, 빠른 수행 가능\n",
    "    - 따라서 이러한 특성때문에 n_estimator와 상호 보완적으로 조합해 사용한다.\n",
    "        - learning_rate를 작게하고 n_estimators를 크게 하면 더 이상 성능이 좋아지지 않는 한계점까지는 예측성능이 조금씩 좋아질 수 있으나 시간이 오래걸리고 성능 역시 현격히 좋아지지는 않음\n",
    "\n",
    "\n",
    "- n_estimators : weak learner의 개수\n",
    "    - weak learner가 순차적으로 오류를 보정하므로 개수가 많을수록 예측 성능이 일정 수준까지는 좋아질 수 있지만, 개수가 많을 수록 시간 오래걸림\n",
    "    \n",
    "\n",
    "- subsample : weak learner가 학습에 사용하는 데이터의 샘플링 비율\n",
    "    - 기본값 1, 이는 전체 학습 데이터를 기반으로 학습한다는 의미 \n",
    "    - 과적합이 염려되는 경우 1보다 작은 값으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용해 하이퍼 파라미터를 최적화\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [100, 500],\n",
    "    'learning_rate' : [0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf, parma_gird=params, cv=2, verbose=1)\n",
    "gird_cv.fit(X_train, y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 설정 그대로 테스트 데이터 세트에 적용해 에측 정확도 확인\n",
    "\n",
    "# GridSearchCV를 이용해 최적으로 학습된 estimator로 예측 수행\n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합에도 강한 뛰어난 예측 성능을 가진 알고리즘이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
