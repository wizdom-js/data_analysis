{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 09. 추천 시스템\n",
    "## 04. 잠재 요인 협업 필터링\n",
    "### 잠재 요인 협업 필터링의 이해\n",
    "#### 잠재 요인 협업 필터링\n",
    ": 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법\n",
    "- '잠재 요인'을 기반으로 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재 요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬(잠재 요인-아이템 행렬)로 분해할 수 있으며, 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성하는 것이 잠재 요인 협력 필터링 알고리즘의 골자이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 분해의 이해\n",
    "- **행렬 분해** : 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법\n",
    "    - 대표적으로 **SVD, NMF 등**이 있다. (주로 SVD방식 이용)\n",
    "    - 하지만 SVD는 널 값이 없는 행렬에만 적용할 수 있다. 그래서 확률적 경사 하강법이나 ALS 방식을 이용해 SVD를 수행한다.\n",
    "- **분해**는 인수분해를 말한다. 인수분해란 일반적으로 하나의 복잡한 식을 두개 이상의 좀 더 단순한 인수의 곱으로 분해하는 것을 말한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 책 참고(573p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법을 이용한 행렬 분해\n",
    ": P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용함수 최적화를 통해 P와 Q를 유추해 내는것\n",
    "- 확률적 경사 하강법을 이용한 행렬 분해의 전반적인 절차\n",
    "    1. P와 Q를 임의의 값을 가진 행렬로 설정\n",
    "    2. P와 Q.T값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 해당하는 오류 값 계산\n",
    "    3. 이 오류 값을 최소화할 수 있도록 P와 Q행렬을 적절한 값으로 각각 업데이트\n",
    "    4. 만족할만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 규제를 반영해 실제 R 행렬 값과 예측 R 행렬 값의 차이를 최소화하는 방향성을 가지고 P행렬과 Q행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R 행렬을 구하는 방식이 **SGD 기반의 행렬분해**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD를 이용해 행렬 분해를 수행하는 예제\n",
    "# 분해하려는 원본 행렬 R을 P와 Q로 분해한 뒤에 다시 P와 Q.T의 내적으로 예측 행렬을 만드는 예제\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3 설정. \n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "num_users, num_items = R.shape\n",
    "K=3\n",
    "\n",
    "# P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 random한 값으로 입력합니다. \n",
    "np.random.seed(1)\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 R 행렬과 예측 행렬의 오차를 구하는 함수\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  3.2388050277987723\n",
      "### iteration step :  50  rmse :  0.4876723101369648\n",
      "### iteration step :  100  rmse :  0.1564340384819247\n",
      "### iteration step :  150  rmse :  0.07455141311978046\n",
      "### iteration step :  200  rmse :  0.04325226798579314\n",
      "### iteration step :  250  rmse :  0.029248328780878973\n",
      "### iteration step :  300  rmse :  0.022621116143829466\n",
      "### iteration step :  350  rmse :  0.019493636196525135\n",
      "### iteration step :  400  rmse :  0.018022719092132704\n",
      "### iteration step :  450  rmse :  0.01731968595344266\n",
      "### iteration step :  500  rmse :  0.016973657887570753\n",
      "### iteration step :  550  rmse :  0.016796804595895633\n",
      "### iteration step :  600  rmse :  0.01670132290188466\n",
      "### iteration step :  650  rmse :  0.01664473691247669\n",
      "### iteration step :  700  rmse :  0.016605910068210026\n",
      "### iteration step :  750  rmse :  0.016574200475705\n",
      "### iteration step :  800  rmse :  0.01654431582921597\n",
      "### iteration step :  850  rmse :  0.01651375177473524\n",
      "### iteration step :  900  rmse :  0.01648146573819501\n",
      "### iteration step :  950  rmse :  0.016447171683479155\n"
     ]
    }
   ],
   "source": [
    "# SGD 기반으로 행렬 분해 수행\n",
    "\n",
    "# 먼저 R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "\n",
    "steps=1000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "\n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 행렬:\n",
      " [[3.991 0.897 1.306 2.002 1.663]\n",
      " [6.696 4.978 0.979 2.981 1.003]\n",
      " [6.677 0.391 2.987 3.977 3.986]\n",
      " [4.968 2.005 1.006 2.017 1.14 ]]\n"
     ]
    }
   ],
   "source": [
    "# 분해된 P와 Q 함수를 P*Q.T로 예측 행렬을 만들어 출력\n",
    "\n",
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 행렬과 비교해 널이 아닌 값은 큰 차이가 나지 않으며, 널인 값은 새로운 예측값으로 채워졌다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 행렬 분해를 이용한 잠재 요인 협업 필터링 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자가 평점을 매기지 않은 널 데이터가 많기 때문에 SGD 기반의 행렬 분해를 구현하고 이를 기반으로 사용자에게 영화 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞 4절에서의 실제 R 행렬과 예측 행렬의 오차를 구하는 함수\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    \n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 분해 로직 새로운 함수로 정리 \n",
    "\n",
    "def matrix_factorization(R, K, steps=200, learning_rate=0.01, r_lambda = 0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. \n",
    "    np.random.seed(1)\n",
    "    P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "    Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    "\n",
    "    break_count = 0\n",
    "       \n",
    "    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. \n",
    "    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "   \n",
    "    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "    for step in range(steps):\n",
    "        for i, j, r in non_zeros:\n",
    "            # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "            eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "            # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "       \n",
    "        rmse = get_rmse(R, P, Q, non_zeros)\n",
    "        if (step % 10) == 0 :\n",
    "            print(\"### iteration step : \", step,\" rmse : \", rmse)\n",
    "            \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('/Users/wizdom/Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv('/Users/wizdom/Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/ml-latest-small/ratings.csv')\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "ratings_matrix = ratings.pivot_table('rating', index='userId', columns='movieId')\n",
    "\n",
    "# title 컬럼을 얻기 이해 movies 와 조인 수행\n",
    "rating_movies = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "# columns='title' 로 title 컬럼으로 pivot 수행. \n",
    "ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  2.9023619751336867\n",
      "### iteration step :  10  rmse :  0.7335768591017927\n",
      "### iteration step :  20  rmse :  0.5115539026853442\n",
      "### iteration step :  30  rmse :  0.37261628282537446\n",
      "### iteration step :  40  rmse :  0.29608182991810134\n",
      "### iteration step :  50  rmse :  0.2520353192341642\n",
      "### iteration step :  60  rmse :  0.22487503275269854\n",
      "### iteration step :  70  rmse :  0.20685455302331535\n"
     ]
    }
   ],
   "source": [
    "# 위의 함수를 이용해 행렬 분해\n",
    "\n",
    "P, Q = matrix_factorization(ratings_matrix.values, K=50, steps=200, learning_rate=0.01, r_lambda = 0.01)\n",
    "pred_matrix = np.dot(P, Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 예측 사용자-아이템 평점 행렬을 영화 타이틀을 칼럼명으로 가지는 데이터프레임으로 변경\n",
    "\n",
    "ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings_matrix.index,\n",
    "                                   columns = ratings_matrix.columns)\n",
    "\n",
    "ratings_pred_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06절의 관람하지 않은 영화 추출 함수 사용\n",
    "\n",
    "def get_unseen_movies(ratings_matrix, userId):\n",
    "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
    "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
    "    user_rating = ratings_matrix.loc[userId,:]\n",
    "    \n",
    "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
    "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
    "    \n",
    "    # 모든 영화명을 list 객체로 만듬. \n",
    "    movies_list = ratings_matrix.columns.tolist()\n",
    "    \n",
    "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
    "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
    "    \n",
    "    return unseen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6절의 잠재 요인 협업 필터링 함수 사용\n",
    "\n",
    "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
    "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
    "    # 가장 예측 평점이 높은 순으로 정렬함. \n",
    "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    return recomm_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rear Window (1954)</th>\n",
       "      <td>5.704612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Park: Bigger, Longer and Uncut (1999)</th>\n",
       "      <td>5.451100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rounders (1998)</th>\n",
       "      <td>5.298393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blade Runner (1982)</th>\n",
       "      <td>5.244951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roger &amp; Me (1989)</th>\n",
       "      <td>5.191962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gattaca (1997)</th>\n",
       "      <td>5.183179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben-Hur (1959)</th>\n",
       "      <td>5.130463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rosencrantz and Guildenstern Are Dead (1990)</th>\n",
       "      <td>5.087375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big Lebowski, The (1998)</th>\n",
       "      <td>5.038690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode V - The Empire Strikes Back (1980)</th>\n",
       "      <td>4.989601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    pred_score\n",
       "title                                                         \n",
       "Rear Window (1954)                                    5.704612\n",
       "South Park: Bigger, Longer and Uncut (1999)           5.451100\n",
       "Rounders (1998)                                       5.298393\n",
       "Blade Runner (1982)                                   5.244951\n",
       "Roger & Me (1989)                                     5.191962\n",
       "Gattaca (1997)                                        5.183179\n",
       "Ben-Hur (1959)                                        5.130463\n",
       "Rosencrantz and Guildenstern Are Dead (1990)          5.087375\n",
       "Big Lebowski, The (1998)                              5.038690\n",
       "Star Wars: Episode V - The Empire Strikes Back ...    4.989601"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 사용자가 관람하지 않는 영화명 추출   \n",
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천 \n",
    "recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, unseen_list, top_n=10)\n",
    "\n",
    "# 평점 데이타를 DataFrame으로 생성. \n",
    "recomm_movies = pd.DataFrame(data=recomm_movies.values,index=recomm_movies.index,columns=['pred_score'])\n",
    "recomm_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
